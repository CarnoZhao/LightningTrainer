name: sia_pv2d_mos
version: f0
fold: &fold 0
seed: 0

norm_cfg: &norm_cfg {type: BN, requires_grad: True}
model:
  type: MMSegSiamese
  backbone:
    type: mmseg.PyramidVisionTransformerV2
    in_chans: 3
    model_name: b2
    pretrained: ./weights/pvt_v2_b2.pth
  decode_head:
    type: DAFormerHead
    channels: 256
    dropout_ratio: 0.1
    num_classes: 1
    norm_cfg: *norm_cfg
    align_corners: False
    decoder_params:
      embed_dims: 256
      embed_cfg: {type: mlp, act_cfg: null, norm_cfg: null}
      embed_neck_cfg: {type: mlp, act_cfg: null, norm_cfg: null}
      fusion_cfg: 
        type: conv
        kernel_size: 3
        act_cfg: {type: ReLU}
        norm_cfg: *norm_cfg

loss: [
  {
    type: BCEWithIgnoreLoss, 
    loss_name: bce_loss, 
    ignore_index: 255, 
    loss_weight: 1.0,
  }, 
  {
    type: DiceLoss, 
    loss_name: dice_loss, 
    loss_weight: 1.0, 
  }
]

metric: 
  type: ChangeAP
  thres_list: [0.2]

data:
  type: SiameseData
  fold: *fold
  num_folds: 5
  batch_size: 24
  stratified_by: null
  group_by: null
  dataset:
    resize: &resize 512
    trans: {
      train: [
        {type: Resize, height: *resize, width: *resize},
        {type: HorizontalFlip, p: 0.5},
        {type: VerticalFlip, p: 0.5},
        {type: RandomRotate90, p: 0.5},
        # {type: ShiftScaleRotate, rotate_limit: 45, border_mode: 0, value: 0, mask_value: 0, p: 0.5},
        {type: OneOf, transforms: [
          {type: ElasticTransform, p: 0.5},
          {type: GridDistortion, p: 0.5},
          # {type: OpticalDistortion, p: 0.5},
        ], p: 1.0},
        {type: Mosaic, p: 0.5},
        {type: ColorJitter, p: 0.5},
        {type: GaussNoise, p: 0.5},
        {type: Normalize},
        {type: ToTensorV2},
      ],
      val: [
        {type: Resize, height: *resize, width: *resize},
        {type: Normalize},
        {type: ToTensorV2},
      ],
      trans_args: {
        additional_targets: {imageB: image}
      }
    }

train:
  # optimizer
  optimizer: adam
  learning_rate: 1e-3
  weight_decay: 2e-5

  # scheduler
  num_epochs: 50
  scheduler: one_cycle

  # trainer
  monitor: val_ap
  log_step: 50
  val_interval: 5
  swa: True
  grad_clip: 2.0
  strategy: dp
  save_topk: 1
